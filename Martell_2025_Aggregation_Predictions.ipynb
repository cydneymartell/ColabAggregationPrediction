{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPRMw1RkHuheD+FNt3+/UY3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cydneymartell/ColabAggregationPrediction/blob/main/Martell_2025_Aggregation_Predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aggregation predictions using models from [Martell et al. 2025](https://www.biorxiv.org/content/10.1101/2025.11.11.687847v1)\n",
        "\n",
        "### This script generates predictions for 50 &deg;C, 75 &deg;C or pH 4 aggregation for protein sequences. Additionally for a protein of interest you can predict a deep mutational scan and plot the predictions.\n",
        "\n"
      ],
      "metadata": {
        "id": "3sceVG_KgbKw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Portions of this workflow incorporate scripts and adapted functions from SaProtHub (Su et al., 2024), which provides a framework for training and using fine-tuned SaProt models.\n",
        "\n",
        "##### Su, J., Li, Z., Han, C., Zhou, Y., Shan, J., Zhou, X., Ma, D., The OPMC, Ovchinnikov, S., & Yuan, F. (2024). SaProtHub: Making Protein Modeling Accessible to All Biologists.\n",
        "\n",
        "##### This workflow also incorporates scripts from ThermoMPNN to predict stability changes.\n",
        "\n",
        "##### Dieckhaus, H., Brocidiacono, M., Randolph, N. Z., & Kuhlman, B. (2024). Transfer learning to leverage larger datasets for improved prediction of protein stability changes. Proceedings of the National Academy of Sciences, 121(6), e2314853121. https://doi.org/10.1073/pnas.2314853121"
      ],
      "metadata": {
        "id": "E_9AxLiVHbIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Aggregation Predictions**"
      ],
      "metadata": {
        "id": "f1XMeUqHVI0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install SaProt and Requirements\n",
        "import subprocess\n",
        "import os, sys\n",
        "from tqdm.notebook import tqdm\n",
        "from google.colab import files\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Markdown, clear_output\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.colors import TwoSlopeNorm\n",
        "from io import StringIO\n",
        "\n",
        "root_dir = os.getcwd()\n",
        "saprot_path = os.path.join(root_dir, \"SaprotHub\")\n",
        "\n",
        "# Clone SaProtHub repository if it is missing\n",
        "if not os.path.exists(saprot_path):\n",
        "    !git clone https://github.com/westlake-repl/SaprotHub.git -q\n",
        "if saprot_path not in sys.path:\n",
        "    sys.path.append(saprot_path)\n",
        "\n",
        "#Tests importing saprot\n",
        "try:\n",
        "    import saprot\n",
        "    print(\"Saprot imported successfully!\")\n",
        "except Exception as e:\n",
        "    print(\"Import failed:\", e)\n",
        "#!pip install -r SaprotHub/requirements.txt -q -q\n",
        "print(\"Installing requirements...\")\n",
        "subprocess.run(\n",
        "    [\"pip\", \"install\", \"-r\", \"SaprotHub/requirements.txt\", \"-q\", \"-q\"],\n",
        "    stdout=subprocess.DEVNULL\n",
        ")\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel,EsmForProteinFolding\n",
        "import torch.nn as nn\n",
        "from huggingface_hub import snapshot_download\n",
        "from pathlib import Path\n",
        "import json\n",
        "import copy\n",
        "from saprot.config.config_dict import Default_config\n",
        "from saprot.scripts.training import my_load_model\n",
        "from saprot.config.config_dict import Default_config\n",
        "\n"
      ],
      "metadata": {
        "id": "iAojN5xm2TSl",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.foldseek_util import get_struc_seq\n",
        "import tempfile\n",
        "import zipfile\n",
        "import re\n",
        "#@title Generate Structurally Aware (SA) Sequences\n",
        "#@markdown #### (Optional) You only need to generate this once and can input the saved structurally aware sequences for predictions below.\n",
        "#@markdown #### For multiple structures, the following need to be uploaded:\n",
        "#@markdown 1. **A ZIP file** containing PDB or CIF structure files\n",
        "#@markdown 2. **A CSV file** with the following columns:\n",
        "#@markdown    - `file_name` – The name of the structure file for that protein (e.g., protein1.pdb).\n",
        "#@markdown    - `chain` – The specific chain to analyze.\n",
        "#@markdown    - `AF_predicted` – Indicates whether the structure is AlphaFold-predicted (True or False).\n",
        "\n",
        "#@markdown ### Select structure upload\n",
        "Num_structures = \"Single Structure\"  # @param ['Single Structure', 'Multiple Structures']\n",
        "\n",
        "display(Markdown(\"### Enter your structure information\"))\n",
        "\n",
        "#Inputs for multiple structures\n",
        "if Num_structures == \"Multiple Structures\":\n",
        "  display(Markdown(\"### Upload ZIP of PDB files\"))\n",
        "\n",
        "  pdb_zip_upload = files.upload()\n",
        "  if pdb_zip_upload:\n",
        "      zip_name = list(pdb_zip_upload.keys())[0]\n",
        "      zip_bytes = pdb_zip_upload[zip_name]\n",
        "\n",
        "      with tempfile.NamedTemporaryFile(suffix=\".zip\", delete=False) as tmp:\n",
        "          tmp.write(zip_bytes)\n",
        "          pdb_zip_path = tmp.name\n",
        "\n",
        "      display(Markdown(f\"**Uploaded PDB ZIP:** {zip_name}\"))\n",
        "\n",
        "  display(Markdown(\"### Upload CSV specifying structure type, chain, and file name\"))\n",
        "  display(Markdown(\"\"\"CSV must include the following columns:\n",
        "\n",
        "        - 'file_name' – The name of the pdb file for that protein (e.g., `protein1.pdb`).\n",
        "        - 'chain' – The specific chain to analyze.\n",
        "        - 'AF_predicted' – Indicates whether the structure is AlphaFold-predicted (`True` or `False`).\n",
        "        \"\"\"))\n",
        "  uploaded = files.upload()\n",
        "  if uploaded:\n",
        "      file_name = list(uploaded.keys())[0]\n",
        "      uploaded_csv = pd.read_csv(StringIO(uploaded[file_name].decode(\"utf-8\")))\n",
        "      display(Markdown(f\"**Uploaded CSV:** {file_name} ({len(uploaded_csv)} rows)\"))\n",
        "\n",
        "  output_area_sa = widgets.Output()\n",
        "  display(output_area_sa)\n",
        "\n",
        "#Inputs for a single structure\n",
        "elif Num_structures == \"Single Structure\":\n",
        "\n",
        "  #Chain input\n",
        "  chain_box = widgets.Text(\n",
        "      placeholder=\"Enter chain\",\n",
        "      description=\"Chain:\",\n",
        "      layout=widgets.Layout(width=\"400px\")\n",
        "  )\n",
        "  display(chain_box)\n",
        "\n",
        "  #Alphafold Selection; masks residues with low plddt\n",
        "  AF_dropdown = widgets.Dropdown(\n",
        "      options=[('Yes (True)', True), ('No (False)', False)],\n",
        "      value=False,\n",
        "      description=\"AlphaFold-Predicted?\",\n",
        "      layout=widgets.Layout(width=\"300px\"),style={'description_width': '150px'}\n",
        "  )\n",
        "  display(AF_dropdown)\n",
        "\n",
        "  #Upload PDB File\n",
        "  #upload_btn = widgets.Button(description=\"Upload PDB File\")\n",
        "  #display(upload_btn)\n",
        "  uploaded = files.upload()\n",
        "\n",
        "  output_area_sa = widgets.Output()\n",
        "  display(output_area_sa)\n",
        "\n",
        "generate_btn = widgets.Button(\n",
        "        description=\"Generate SA Sequences\",\n",
        "        layout=widgets.Layout(width=\"300px\", height=\"40px\",)\n",
        "    )\n",
        "generate_btn.button_style = 'success'\n",
        "display(generate_btn)\n",
        "\n",
        "#Foldseek path\n",
        "foldseek_path = \"/content/SaprotHub/bin/foldseek\"\n",
        "!chmod +x /content/SaprotHub/bin/foldseek\n",
        "\n",
        "from Bio.PDB import MMCIFParser, PDBIO\n",
        "\n",
        "def convert_cif_to_pdb(cif_bytes):\n",
        "    parser = MMCIFParser(QUIET=True)\n",
        "    structure = parser.get_structure(\"structure\", StringIO(cif_bytes.decode(\"utf-8\")))\n",
        "\n",
        "    pdb_io = PDBIO()\n",
        "    tmp = tempfile.NamedTemporaryFile(suffix=\".pdb\", delete=False)\n",
        "    pdb_io.set_structure(structure)\n",
        "    pdb_io.save(tmp.name)\n",
        "    return tmp.name\n",
        "\n",
        "def on_generate_click(b):\n",
        "    #Generates structurally aware sequence for a single protein\n",
        "    if Num_structures == \"Single Structure\":\n",
        "      file_name = list(uploaded.keys())[0]\n",
        "      raw_bytes = uploaded[file_name]\n",
        "\n",
        "      if file_name.endswith(\".cif\"):\n",
        "          pdb_path = convert_cif_to_pdb(raw_bytes)\n",
        "      else:\n",
        "          file_name = list(uploaded.keys())[0]\n",
        "          pdb_content = uploaded[file_name].decode(\"utf-8\")\n",
        "\n",
        "          with tempfile.NamedTemporaryFile(suffix=\".pdb\", delete=False) as tmp:\n",
        "              tmp.write(pdb_content.encode(\"utf-8\"))\n",
        "              pdb_path = tmp.name\n",
        "\n",
        "      chain = chain_box.value.strip()\n",
        "      AF_bool = AF_dropdown.value\n",
        "\n",
        "      with output_area_sa:\n",
        "          output_area_sa.clear_output()\n",
        "          if not chain:\n",
        "              print(\"Please enter the chain\")\n",
        "              return\n",
        "          try:\n",
        "              seq_dict = get_struc_seq(foldseek_path, pdb_path, [chain], plddt_mask=AF_bool)\n",
        "              seq, foldseek_seq, combined_seq = seq_dict[chain]\n",
        "              print(\"Sequence:\", seq)\n",
        "              print(\"Foldseek sequence:\", foldseek_seq)\n",
        "              print(\"Combined structurally aware (SA) sequence:\", combined_seq)\n",
        "          except Exception as e:\n",
        "              print(\"Error:\", e)\n",
        "    #Generates structurally aware sequence for many proteins\n",
        "    elif Num_structures == \"Multiple Structures\":\n",
        "      if not pdb_zip_upload:\n",
        "                print(\"Please upload a ZIP file.\")\n",
        "                return\n",
        "      if uploaded_csv is None:\n",
        "          print(\"Please upload a CSV file.\")\n",
        "          return\n",
        "\n",
        "      print(\"Extracting PDB ZIP...\")\n",
        "      extract_dir = tempfile.mkdtemp()\n",
        "      with zipfile.ZipFile(pdb_zip_path, 'r') as z:\n",
        "          z.extractall(extract_dir)\n",
        "      print(f\"Extracted to: {extract_dir}\\n\")\n",
        "\n",
        "      names = []\n",
        "      sequences = []\n",
        "      sa = []\n",
        "      #Generates structurally aware sequences for all pdbs\n",
        "      for i, row in uploaded_csv.iterrows():\n",
        "        pdb_file = row[\"file_name\"]\n",
        "        chain = str(row[\"chain\"])\n",
        "        AF_bool = bool(row[\"AF_predicted\"])\n",
        "\n",
        "        # Full path to PDB inside extracted ZIP\n",
        "        pdb_path = os.path.join(extract_dir, pdb_file)\n",
        "\n",
        "        if not os.path.exists(pdb_path):\n",
        "            print(f\"Missing PDB: {pdb_file}\")\n",
        "            continue\n",
        "\n",
        "        #print(f\"Processing: {pdb_file}, chain {chain}, AF={AF_bool}\")\n",
        "        try:\n",
        "            seq, foldseek_seq, combined_seq = get_struc_seq(\n",
        "                foldseek_path,\n",
        "                pdb_path,\n",
        "                [chain],\n",
        "                plddt_mask=AF_bool\n",
        "            )[chain]\n",
        "\n",
        "            names.append(pdb_file.split('/')[-1])\n",
        "\n",
        "            sequences.append(seq)\n",
        "            sa.append(combined_seq)\n",
        "\n",
        "        except Exception as e:\n",
        "                    print(f\"Failed: {e}\")\n",
        "\n",
        "      #Save dataframe of structurally aware sequences and downloads the dataframe\n",
        "      df = pd.DataFrame(zip(names, sequences, sa), columns = [\"ID\",\"seq_no_sa\",\"protein\"])\n",
        "      df.to_csv(\"structurally_aware_sequences.csv\", index=False)\n",
        "      files.download(\"structurally_aware_sequences.csv\")\n",
        "      print(f\"Downloaded to structurally_aware_sequences.csv\")\n",
        "generate_btn.on_click(on_generate_click)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1XMez1vgmpsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title Load Aggregation Model\n",
        "#@markdown #### Fine-tuned adapters are deposited on [HuggingFace](https://hf.co/collections/cmartell/martell-et-al-2025-aggregation-models-and-datasets)\n",
        "#Function to initialize the saprot regression model based on the LoRA configs\n",
        "def model_initialization(base_model, lora_kwargs):\n",
        "  config = copy.deepcopy(Default_config)\n",
        "  config.model.model_py_path = \"saprot/saprot_regression_model\"\n",
        "  config.model.kwargs.config_path = base_model\n",
        "  config.model.kwargs.lora_kwargs = lora_kwargs\n",
        "  model = my_load_model(config.model)\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  model.to(device)\n",
        "  model.eval()\n",
        "\n",
        "  return model, device\n",
        "\n",
        "#Function to predict aggregation for multiple protein sequences\n",
        "def predict_aggregation_multiple(sequences, base_model, lora_kwargs):\n",
        "\n",
        "  model, device = model_initialization(base_model, lora_kwargs)\n",
        "\n",
        "  #Tokenizes all protein sequences\n",
        "  all_inputs = tokenizer(\n",
        "    sequences.tolist(),\n",
        "    return_tensors=\"pt\",\n",
        "    padding=True,\n",
        "    truncation=True\n",
        "    ).to(device)\n",
        "  #Makes predictions for each protein\n",
        "  pred_labels =[]\n",
        "  for i in tqdm(range(len(sequences))):\n",
        "    input_i = {k: v[i].unsqueeze(0) for k, v in all_inputs.items()}  # keep batch dim\n",
        "    with torch.no_grad():\n",
        "        pred = model(input_i)\n",
        "        pred_labels.append(pred.item())\n",
        "  return pred_labels\n",
        "\n",
        "#Function to predict aggregation for a single protein sequence\n",
        "def predict_aggregation_single(sa_seq,base_model, lora_kwargs):\n",
        "\n",
        "  model, device = model_initialization(base_model, lora_kwargs)\n",
        "\n",
        "  #Tokenize and make prediction\n",
        "  inputs = tokenizer(sa_seq, return_tensors=\"pt\").to(device)\n",
        "  inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "  with torch.no_grad():\n",
        "    pred = model(inputs)\n",
        "  pred_labels = pred.item()\n",
        "\n",
        "  return pred_labels\n",
        "\n",
        "#Selection for aggregation stress prediction\n",
        "#@markdown #### <br>Select Aggregation Model\n",
        "Aggregation_stress = \"50 C Aggregation\"  # @param ['50 C Aggregation', '75 C Aggregation', 'pH 4 Aggregation']\n",
        "\n",
        "ADAPTER_HOME = Path(f'{root_dir}/SaprotHub/adapters')\n",
        "model_dict = {\n",
        "    '50 C Aggregation': 'cmartell/Model-50C_Aggregation-650M',\n",
        "    '75 C Aggregation': 'cmartell/Model-75C_Aggregation-650M',\n",
        "    'pH 4 Aggregation': 'cmartell/Model-pH4_Aggregation-650M'\n",
        "}\n",
        "model_arg = model_dict[Aggregation_stress]\n",
        "snapshot_download(repo_id=model_arg, repo_type=\"model\",local_dir=ADAPTER_HOME/model_arg)\n",
        "\n",
        "adapter_path = ADAPTER_HOME/model_arg\n",
        "base_model_name = \"westlake-repl/SaProt_650M_AF2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
        "#base_model = AutoModel.from_pretrained(base_model_name)\n",
        "base_model = \"westlake-repl/SaProt_650M_AF2\"\n",
        "lora_kwargs = {\n",
        "  \"is_trainable\": False,\n",
        "  \"num_lora\": 1,\n",
        "  \"config_list\": [{\"lora_config_path\": adapter_path}]\n",
        "}\n",
        "\n",
        "metadata_path = Path(adapter_path)/ \"metadata.json\"\n",
        "with open(metadata_path, 'r') as f:\n",
        "  metadata = json.load(f)\n",
        "\n",
        "\n",
        "print(\"Fine-tuned adapters loaded successfully\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lMPpK8OOGyAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Make Aggregation Predictions\n",
        "#@markdown #### Predictions can be made for a single protein of interest or multiple sequences. Predictions use the structurally aware (SA) sequence, which can be produced above from the AlphaFold-predicted structure or PDB file.\n",
        "#@markdown #### <br> For multiple-sequence predictions, the uploaded CSV must contain:\n",
        "#@markdown - Column named `protein` with the SA sequences\n",
        "#@markdown - Column named an `ID` with the corresponding protein names\n",
        "#@markdown #### <br> Input Selection\n",
        "Input_type = \"Single SA sequence\"  # @param [\"Single SA sequence\", \"Multiple SA sequences\"]\n",
        "\n",
        "uploaded_name = None\n",
        "uploaded_sequence = None\n",
        "uploaded_csv = None\n",
        "\n",
        "#Inputs for Single SA sequence\n",
        "if Input_type == \"Single SA sequence\":\n",
        "    display(Markdown(\"### Enter your sequence information\"))\n",
        "\n",
        "    # Text input for sequence name\n",
        "    name_box = widgets.Text(\n",
        "        placeholder=\"Enter sequence name\",\n",
        "        description=\"Name:\",\n",
        "        layout=widgets.Layout(width=\"400px\")\n",
        "    )\n",
        "    display(name_box)\n",
        "\n",
        "    # Text area for sequence\n",
        "    seq_box = widgets.Textarea(\n",
        "        placeholder=\"Paste your sequence here\",\n",
        "        description=\"Sequence:\",\n",
        "        layout=widgets.Layout(width=\"600px\", height=\"150px\")\n",
        "    )\n",
        "    display(seq_box)\n",
        "\n",
        "    output_area_pred = widgets.Output()\n",
        "\n",
        "#Input for Multiple sequences\n",
        "elif Input_type == \"Multiple SA sequences\":\n",
        "    display(Markdown(\"###Upload a CSV file containing multiple sequences\"))\n",
        "\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        file_name = list(uploaded.keys())[0]\n",
        "        uploaded_csv = pd.read_csv(StringIO(uploaded[file_name].decode(\"utf-8\")))\n",
        "        display(Markdown(f\"**Uploaded CSV:** {file_name} ({len(uploaded_csv)} rows)\"))\n",
        "\n",
        "\n",
        "predict_button = widgets.Button(description=\"Make Predictions\", button_style=\"success\", disabled=False)\n",
        "output_area_pred = widgets.Output()\n",
        "\n",
        "def on_predict_click(b):\n",
        "    output_area_pred.clear_output()\n",
        "    with output_area_pred:\n",
        "        #Predictions for single sequence\n",
        "        if Input_type == \"Single SA sequence\":\n",
        "            uploaded_name = name_box.value.strip()\n",
        "            uploaded_sequence = seq_box.value.strip()\n",
        "            if uploaded_name and uploaded_sequence:\n",
        "              display(Markdown(f\"Running prediction on single sequence: {uploaded_name}\"))\n",
        "              result = predict_aggregation_single(uploaded_sequence, base_model, lora_kwargs)\n",
        "              pd.DataFrame([[uploaded_name,uploaded_sequence, result]], columns=[\"ID\",\"protein\", \"score\"]).to_csv(f\"{uploaded_name}_predictions.csv\", index=False)\n",
        "              files.download(f\"{uploaded_name}_predictions.csv\")\n",
        "              print(f\"Aggregation prediction for {uploaded_name} is {result:.3f}\")\n",
        "              display(Markdown(\"Predictions were downloaded as \" + f\"{uploaded_name}_predictions.csv\"))\n",
        "        #Predictions for multiple sequences\n",
        "        elif uploaded_csv is not None:\n",
        "            display(Markdown(f\"Running prediction on {len(uploaded_csv)} sequences from CSV\"))\n",
        "            result = predict_aggregation_multiple(uploaded_csv[\"protein\"], base_model, lora_kwargs)\n",
        "            uploaded_csv[\"score\"] =result\n",
        "            uploaded_csv.to_csv(f\"predictions.csv\", index=False)\n",
        "            files.download(\"predictions.csv\")\n",
        "            display(Markdown(f\"Predictions were downloaded as predictions.csv\"))\n",
        "        else:\n",
        "            display(Markdown(\"No input detected.\"))\n",
        "\n",
        "predict_button.on_click(on_predict_click)\n",
        "display(predict_button, output_area_pred)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZjkJPGCTKgFY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Make Aggregation DMS Predictions\n",
        "#@markdown #### Predicts aggregation for all single point mutants for a protein of interest. These predictions use the structurally aware sequence using the wild-type structure for each mutant prediction.\n",
        "\n",
        "#generate DMS sequences\n",
        "def generate_dms_SA_seq(seq, name):\n",
        "    AA = [\"A\",\"T\",\"S\",\"V\",\"I\",\"K\",\"P\",\"Y\",\"M\",\"N\",\"H\",\"G\",\"F\",\"R\",\"D\",\"E\",\"W\",\"Q\",\"L\"]\n",
        "\n",
        "    dms_seq =[seq]\n",
        "    names =[name]\n",
        "    original_AA = [\"wt\"]\n",
        "    mutant_AA = [\"wt\"]\n",
        "    position_mut = [\"wt\"]\n",
        "\n",
        "    wt_s = seq\n",
        "    seq = ''\n",
        "\n",
        "    #Iterates through all amino acids\n",
        "    for a in range(len(AA)):\n",
        "        seq = \"\"\n",
        "        count = 1\n",
        "\n",
        "        #Iterates through each wt poisiton\n",
        "        for i, chr in enumerate(wt_s):\n",
        "          if chr.isupper():\n",
        "            if a != chr:\n",
        "              if i == 1:\n",
        "                seq = AA[a] + wt_s[i+1:]\n",
        "                position_mut.append(count)\n",
        "                mutant_AA.append(AA[a])\n",
        "                original_AA.append(chr)\n",
        "                dms_seq.append(seq)\n",
        "              else:\n",
        "                seq = wt_s[:i] + AA[a] + wt_s[i+1:]\n",
        "                position_mut.append(count)\n",
        "                mutant_AA.append(AA[a])\n",
        "                original_AA.append(chr)\n",
        "                dms_seq.append(seq)\n",
        "              names.append(name + \"_\"+ chr + str(count)+ AA[a] )\n",
        "              count+=1\n",
        "    df_dms = pd.DataFrame(list(zip(names, dms_seq, original_AA, position_mut, mutant_AA)), columns=[\"ID\",\"protein\",\"original_AA\",\"position_mut\",\"mutant_AA\"])\n",
        "    return(df_dms)\n",
        "\n",
        "\n",
        "display(Markdown(\"### Enter your sequence information\"))\n",
        "name_box = widgets.Text(\n",
        "    placeholder=\"Enter sequence name\",\n",
        "    description=\"Name:\",\n",
        "    layout=widgets.Layout(width=\"400px\")\n",
        ")\n",
        "seq_box = widgets.Textarea(\n",
        "    placeholder=\"Paste your sequence here\",\n",
        "    description=\"Sequence:\",\n",
        "    layout=widgets.Layout(width=\"600px\", height=\"150px\")\n",
        ")\n",
        "display(name_box, seq_box)\n",
        "dms_button = widgets.Button(description=\"Generate DMS Predictions\", button_style=\"success\", disabled=False)\n",
        "output_area_dms = widgets.Output()\n",
        "\n",
        "df_dms = None\n",
        "\n",
        "#Predictions aggregation for dms scan\n",
        "def on_dms_click(b):\n",
        "    global df_dms\n",
        "    output_area_dms.clear_output()\n",
        "    with output_area_dms:\n",
        "\n",
        "      uploaded_name = name_box.value.strip()\n",
        "      uploaded_sequence = seq_box.value.strip()\n",
        "      if uploaded_name and uploaded_sequence:\n",
        "        display(Markdown(f\"Running DMS predictions on protein: {uploaded_name}\"))\n",
        "        df_dms = generate_dms_SA_seq(uploaded_sequence, uploaded_name)\n",
        "        result = predict_aggregation_multiple(df_dms[\"protein\"], base_model, lora_kwargs)\n",
        "        df_dms[\"score\"] =result\n",
        "        df_dms.to_csv(f\"/content/{uploaded_name}_agg_dms_predictions.csv\", index=False)\n",
        "        files.download(f\"/content/{uploaded_name}_agg_dms_predictions.csv\")\n",
        "        display(Markdown(\"DMS Predictions were downloaded and saved as \" +f\"{uploaded_name}_agg_dms_predictions.csv\"))\n",
        "\n",
        "      else:\n",
        "          display(Markdown(\"No input detected.\"))\n",
        "\n",
        "dms_button.on_click(on_dms_click)\n",
        "display(dms_button, output_area_dms)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "W5012wd3nkt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title Plot Aggregation DMS Predictions\n",
        "#@markdown #### Plots the DMS Predictions for the protein of interest generated above. The heatmap is colored by the Δ log2(Fold Change), where more positive values (green) indicated substitutions predicted to be more aggregation resistant. The black dots indicate the wild type residue at each position. The model does not predict substitions to cysteines because the models weren't trained on proteins with these residues.\n",
        "AminoAcids = ['C', 'D', 'E', 'R','K', 'Q', 'N', 'H','M','A','G', 'S', 'T', 'I',  'L','V', 'F','W', 'Y','P']\n",
        "df_dms[\"no_sa\"]=[c[::2] for c in df_dms[\"protein\"]]\n",
        "pos = np.arange(1,len(df_dms[\"no_sa\"].values[0])+1,1)\n",
        "matrix_agg = np.zeros((len(AminoAcids),len(df_dms[\"no_sa\"].values[0])))\n",
        "xlabel = []\n",
        "wt_score_agg = df_dms.query(\"\"\" position_mut == \"wt\" \"\"\")[\"score\"].values[0]\n",
        "df_dms[\"delta_score\"] = df_dms[\"score\"] - wt_score_agg\n",
        "\n",
        "#Makes the columns the WT amino acid position\n",
        "for col_wt in range(0,len(pos)):\n",
        "    #Iterates through each amino acid substitution as the row\n",
        "    for row_sub in range(len(AminoAcids)):\n",
        "        curr = df_dms.query(\"\"\"  position_mut == {} and mutant_AA == \"{}\" \"\"\".format(pos[col_wt],AminoAcids[row_sub]))\n",
        "\n",
        "        if df_dms.query(\"\"\" position_mut == \"wt\" \"\"\")[\"no_sa\"].values[0][col_wt] == AminoAcids[row_sub]:\n",
        "            curr = df_dms.query(\"\"\" position_mut == \"wt\" \"\"\")\n",
        "            xlabel.append(AminoAcids[row_sub]+str(pos[col_wt]))\n",
        "            wt_score_agg = curr[\"delta_score\"].values[0]\n",
        "        if len(curr) > 0:\n",
        "            matrix_agg[row_sub,col_wt]=curr[\"delta_score\"].values[0]\n",
        "\n",
        "        else:\n",
        "            matrix_agg[row_sub,col_wt]=np.nan\n",
        "\n",
        "#Plot heatmap\n",
        "plt.figure(figsize = (20,4))\n",
        "ax=sns.heatmap(matrix_agg, yticklabels = AminoAcids, xticklabels=xlabel,center = 0,cmap = \"PRGn\",cbar_kws={'label': 'Δ log2(Fold Change)'})\n",
        "\n",
        "n = df_dms.query(\"\"\" position_mut == \"wt\" \"\"\")[\"ID\"].values[0]\n",
        "plt.title(\"Aggregation DMS for \" +n)\n",
        "\n",
        "#Adds scatterplot points for the WT protein sequence\n",
        "wtseq = df_dms.query(\"\"\" position_mut == \"wt\" \"\"\")[\"no_sa\"].values[0]\n",
        "for i in range(len(wtseq)):\n",
        "    plt.scatter(i+0.5,AminoAcids.index(wtseq[i])+0.5, s=30,color='black')\n",
        "\n",
        "plt.savefig(f\"/content/{n}_agg_DMS_heatmap.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Heatmap saved as \"+f\"{df_dms.query(\"\"\" position_mut == \"wt\" \"\"\")[\"ID\"].values[0]}_agg_DMS_heatmap.png\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SP0CR55r8vfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Compare Stability and Aggregation Predictions**"
      ],
      "metadata": {
        "id": "RpMLs9vCVjP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install ThermoMPNN and the Dependencies\n",
        "import yaml\n",
        "target_dir = \"/content/\"\n",
        "\n",
        "# Only change directory if not already there\n",
        "if os.getcwd() != os.path.abspath(target_dir):\n",
        "    os.chdir(target_dir)\n",
        "\n",
        "repo_url = \"https://github.com/Kuhlman-Lab/ThermoMPNN.git\"\n",
        "repo_name = \"ThermoMPNN\"\n",
        "\n",
        "#Clone ThermoMPNN Repo\n",
        "if not os.path.exists(repo_name):\n",
        "    print(\"Cloning ThermoMPNN...\")\n",
        "    !git clone $repo_url -q\n",
        "    print(\"Cloned ThermoMPNN\")\n",
        "    !cd \"ThermoMPNN/analysis\"\n",
        "else:\n",
        "    print(\"ThermoMPNN already exists — skipping clone.\")\n",
        "\n",
        "sys.path.insert(0, \"/content/ThermoMPNN\")\n",
        "\n",
        "#Install Miniconda\n",
        "miniconda_path = \"/content/miniconda\"\n",
        "conda_bin = os.path.join(miniconda_path, \"bin\")\n",
        "\n",
        "if not os.path.exists(miniconda_path):\n",
        "    !wget -q https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O /tmp/miniconda.sh > /dev/null 2>&1\n",
        "    !bash /tmp/miniconda.sh -b -p {miniconda_path} > /dev/null 2>&1\n",
        "    !rm /tmp/miniconda.sh\n",
        "    print(\"Miniconda installed.\")\n",
        "else:\n",
        "    print(\"Miniconda already exists — skipping install.\")\n",
        "\n",
        "\n",
        "os.environ[\"PATH\"] = conda_bin + \":\" + os.environ[\"PATH\"]\n",
        "sys.path.append(conda_bin)\n",
        "\n",
        "!conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main\n",
        "!conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r\n",
        "\n",
        "#Create ThermoMPNN environment\n",
        "env_name = \"thermoMPNN\"\n",
        "yaml_path = \"/content/ThermoMPNN/environment.yaml\"\n",
        "\n",
        "# Check if environment already exists\n",
        "envs_list = !conda env list\n",
        "if env_name in \"\\n\".join(envs_list):\n",
        "    print(f\"\\nEnvironment {env_name} already exists\")\n",
        "else:\n",
        "    print(f\"\\nCreating environment {env_name}...\")\n",
        "    !conda env create -f {yaml_path} -q --yes\n",
        "    !/content/miniconda/envs/thermoMPNN/bin/python -m pip install -q --upgrade --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 > /dev/null 2>&1\n",
        "\n",
        "target_dir = \"/content/ThermoMPNN/analysis\"\n",
        "\n",
        "if os.getcwd() != os.path.abspath(target_dir):\n",
        "    print(f\"Working directory {os.getcwd()}\")\n",
        "    os.chdir(target_dir)\n",
        "    print(f\"Changed working directory to: {os.getcwd()}\")\n",
        "else:\n",
        "    print(f\"Already in the correct directory: {os.getcwd()}\")\n",
        "\n",
        "\n",
        "\n",
        "#Update the model_weights path in the local.yaml\n",
        "yaml_path = \"/content/ThermoMPNN/local.yaml\"\n",
        "with open(yaml_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "config['platform']['thermompnn_dir'] = \"/content/ThermoMPNN\"\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.safe_dump(config, f)\n",
        "print(\"local.yaml updated successfully!\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OXzxMafIVlUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Make DMS stability predictions with ThermoMPNN\n",
        "#@markdown #### Predicts ddG for all single point mutants for a protein of interest. The predictions require the protein structure as input.\n",
        "\n",
        "import glob\n",
        "import shutil\n",
        "from ipywidgets import widgets, Layout\n",
        "\n",
        "\n",
        "#Widgets to upload files and start predictions\n",
        "protein_input = widgets.Text(\n",
        "    description='Protein Name:',\n",
        "    placeholder='Enter protein name',\n",
        "    layout=Layout(width='40%'),style={'description_width': '120px'}\n",
        ")\n",
        "\n",
        "structure_upload_widget = widgets.FileUpload(\n",
        "    description='Upload PDB',\n",
        "    accept='.pdb',\n",
        "    multiple=False\n",
        ")\n",
        "\n",
        "run_button = widgets.Button(\n",
        "    description='Run ThermoMPNN',\n",
        "    button_style='success'\n",
        ")\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "def run_prediction(b):\n",
        "    with output:\n",
        "        clear_output()\n",
        "        if not protein_input.value:\n",
        "            print(\"Please enter a protein name.\")\n",
        "            return\n",
        "        if not structure_upload_widget.value:\n",
        "            print(\"Please upload a PDB file.\")\n",
        "            return\n",
        "\n",
        "        protein_name = protein_input.value\n",
        "        uploaded_file = list(structure_upload_widget.value.values())[0]\n",
        "        pdb_filename = uploaded_file['metadata']['name']\n",
        "        pdb_path = os.path.join('/content', pdb_filename)\n",
        "\n",
        "        # Save uploaded file to content folder\n",
        "        with open(pdb_path, 'wb') as f:\n",
        "            f.write(uploaded_file['content'])\n",
        "\n",
        "        print(f\"Running ThermoMPNN on {pdb_filename} for protein {protein_name}...\")\n",
        "\n",
        "        output_log = f\"/content/{protein_name}_thermompnn_output.log\"\n",
        "\n",
        "        # Run prediction\n",
        "        !/content/miniconda/envs/thermoMPNN/bin/python /content/ThermoMPNN/analysis/custom_inference.py \\\n",
        "            --pdb {pdb_path} \\\n",
        "            --model_path ../models/thermoMPNN_default.pt \\\n",
        "            > {output_log} 2>&1\n",
        "\n",
        "        #Save the prediction to the content folder\n",
        "        csv_files = glob.glob(\"/content/ThermoMPNN/analysis/ThermoMPNN_inference_*.csv\")\n",
        "        if csv_files:\n",
        "            original_csv = csv_files[0]  # take the first (or latest) file\n",
        "            new_csv = f\"/content/{protein_name}_thermoMPNN_predictions.csv\"\n",
        "            shutil.move(original_csv, new_csv)\n",
        "            print(f\"ThermoMPNN prediction complete. Output log saved to {output_log}. Predictions saved to {new_csv}\")\n",
        "        else:\n",
        "            print(f\"No CSV output found. Check if ThermoMPNN ran correctly. Output log saved to {output_log}.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        structure_upload_widget.value.clear()  # clear uploaded files\n",
        "        structure_upload_widget._counter = 0\n",
        "\n",
        "run_button.on_click(run_prediction)\n",
        "\n",
        "\n",
        "display(protein_input, structure_upload_widget, run_button, output)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DQGHshtjVqlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot ThermoMPNN Predictions\n",
        "#@markdown #### Plots the DMS stability predictions for the protein of interest. The heatmap is colored by the ΔΔG, where more negative values (green) indicated substitutions predicted to be stabilizing. The black dots indicate the wild type residue at each position. Substitions to cysteines aren't shown because they aren't predicted for aggregation .\n",
        "\n",
        "thermompnn_predictions = pd.read_csv(f\"/content/{protein_input.value}_thermoMPNN_predictions.csv\")\n",
        "thermompnn_predictions[\"position_mut\"] = [str(p+1) for p in thermompnn_predictions[\"position\"]]\n",
        "thermompnn_predictions[\"mutant_AA\"] = thermompnn_predictions[\"mutation\"]\n",
        "thermompnn_predictions[\"original_AA\"] = thermompnn_predictions[\"wildtype\"]\n",
        "\n",
        "wt_df = thermompnn_predictions[[\"position\", \"wildtype\"]].drop_duplicates().sort_values(\"position\")\n",
        "wt_sequence = \"\".join(wt_df[\"wildtype\"].tolist())\n",
        "thermompnn_predictions[\"no_sa\"] = [wt_sequence for p in range(len(thermompnn_predictions))]\n",
        "AminoAcids = [ 'C','D', 'E', 'R','K', 'Q', 'N', 'H','M','A','G', 'S', 'T', 'I',  'L','V', 'F','W', 'Y','P']\n",
        "pos = np.arange(1,len(thermompnn_predictions[\"no_sa\"].values[0])+1,1)\n",
        "matrix_agg = np.zeros((len(AminoAcids),len(thermompnn_predictions[\"no_sa\"].values[0])))\n",
        "xlabel = []\n",
        "\n",
        "#Makes the columns the WT amino acid position\n",
        "for col_wt in range(0,len(pos)):\n",
        "    #Iterates through each amino acid substitution as the row\n",
        "    for row_sub in range(len(AminoAcids)):\n",
        "        curr = thermompnn_predictions.query(\"\"\"  position_mut == \"{}\" and mutant_AA == \"{}\" \"\"\".format(pos[col_wt],AminoAcids[row_sub]))\n",
        "\n",
        "        if thermompnn_predictions[\"no_sa\"].values[0][col_wt] == AminoAcids[row_sub]:\n",
        "            xlabel.append(AminoAcids[row_sub]+str(pos[col_wt]))\n",
        "            matrix_agg[row_sub,col_wt]=0\n",
        "        if len(curr) > 0:\n",
        "            matrix_agg[row_sub,col_wt]=curr[\"ddG_pred\"].values[0]\n",
        "\n",
        "        else:\n",
        "            matrix_agg[row_sub,col_wt]=np.nan\n",
        "\n",
        "#Plot heatmap\n",
        "plt.figure(figsize = (25,4))\n",
        "ax=sns.heatmap(matrix_agg, yticklabels = AminoAcids, xticklabels=xlabel,center = 0,cmap = \"PRGn_r\",cbar_kws={'label': 'ΔΔG Predictions'})\n",
        "\n",
        "n = protein_input.value\n",
        "plt.title(\"ThermoMPNN DMS for \" +n +\"\\nΔΔG Predictions\")\n",
        "\n",
        "#Adds scatterplot points for the WT protein sequence\n",
        "wtseq = thermompnn_predictions[\"no_sa\"].values[0]\n",
        "for i in range(len(wtseq)):\n",
        "    plt.scatter(i+0.5,AminoAcids.index(wtseq[i])+0.5, s=30,color='black')\n",
        "\n",
        "plt.savefig(f\"{n}_ThermoMPNN_DMS_heatmap.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mzKH2XAnVqvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Combine and Download csv with ThermoMPNN  and Aggregation Predictions\n",
        "#@markdown #### #@title Enter the protein name to combine and download ThermoMPNN and aggregation DMS predictions generated in this session.\n",
        "\n",
        "#Widgets to get protein name\n",
        "protein_name = widgets.Text(\n",
        "    description='Protein Name:',\n",
        "    placeholder='Enter protein name',\n",
        "    layout=widgets.Layout(width='40%'),\n",
        "    style={'description_width': '120px'}\n",
        ")\n",
        "\n",
        "download_button = widgets.Button(\n",
        "    description=\"Download Combined CSV\",\n",
        "    button_style=\"success\",  # green\n",
        "    layout=widgets.Layout(width=\"220px\")\n",
        ")\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "display(protein_name, download_button, output)\n",
        "dfs = {} #Initialize dictionary to store dataframes globally\n",
        "\n",
        "def on_download_clicked(b):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "\n",
        "        n = protein_name.value\n",
        "\n",
        "        if n == \"\":\n",
        "            print(\"Please enter a protein name.\")\n",
        "            return\n",
        "        #Read in thermompnn and aggregation predictions for a protein of interest\n",
        "        try:\n",
        "            thermompnn_predictions = pd.read_csv(f\"/content/{n}_thermoMPNN_predictions.csv\")\n",
        "            aggregation_dms_predictions = pd.read_csv(f\"/content/{n}_agg_dms_predictions.csv\")\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Could not find prediction files for protein: {n}\")\n",
        "            print(f\"Expected the following:\\n  /content/{n}_thermoMPNN_predictions.csv\\n  /content/{n}_agg_dms_predictions.csv\")\n",
        "            return\n",
        "\n",
        "\n",
        "        aggregation_dms_predictions[\"no_sa\"] = [c[::2] for c in aggregation_dms_predictions[\"protein\"]]\n",
        "\n",
        "        wt_score_agg = aggregation_dms_predictions.query(\"position_mut == 'wt'\")[\"score\"].values[0]\n",
        "        aggregation_dms_predictions[\"delta_score\"] = aggregation_dms_predictions[\"score\"] - wt_score_agg\n",
        "\n",
        "        thermompnn_predictions[\"position_mut\"] = [str(p+1) for p in thermompnn_predictions[\"position\"]]\n",
        "        thermompnn_predictions[\"mutant_AA\"] = thermompnn_predictions[\"mutation\"]\n",
        "        thermompnn_predictions[\"original_AA\"] = thermompnn_predictions[\"wildtype\"]\n",
        "\n",
        "        agg_thermompnn = pd.merge(\n",
        "            thermompnn_predictions,\n",
        "            aggregation_dms_predictions,\n",
        "            on=[\"original_AA\", \"position_mut\", \"mutant_AA\"])\n",
        "\n",
        "        agg_thermompnn[\"score_agg\"] = agg_thermompnn[\"score\"]\n",
        "        agg_thermompnn[\"delta_score_agg\"] = agg_thermompnn[\"delta_score\"]\n",
        "        dfs[\"agg\"] = aggregation_dms_predictions\n",
        "        dfs[\"thermo\"] = thermompnn_predictions\n",
        "        dfs[\"merged\"] = agg_thermompnn\n",
        "        if len(agg_thermompnn) != len(aggregation_dms_predictions) - 1:\n",
        "            print(\"Error merging predictions. Check the prediction files.\")\n",
        "            return\n",
        "        output_path = f\"{n}_thermompnn_agg_predictions.csv\"\n",
        "        agg_thermompnn[['ID', 'protein', 'no_sa', 'position_mut', 'mutant_AA','original_AA', 'score_agg', 'delta_score_agg', 'ddG_pred']].to_csv(output_path, index=False)\n",
        "\n",
        "        files.download(output_path)\n",
        "        print(f\"Combined Aggregation and ThermoMPNN predictions downloaded as: {output_path}\")\n",
        "\n",
        "        dfs[\"agg\"] = aggregation_dms_predictions\n",
        "        dfs[\"thermo\"] = thermompnn_predictions\n",
        "        dfs[\"merged\"] = agg_thermompnn\n",
        "\n",
        "download_button.on_click(on_download_clicked)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "p0WuAs2XVq3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Heatmap Comparing ThermoMPNN  and Aggregation Predictions\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.colors as mcolors\n",
        "AminoAcids = [ 'C','D', 'E', 'R','K', 'Q', 'N', 'H','M','A','G', 'S', 'T', 'I',  'L','V', 'F','W', 'Y','P']\n",
        "agg_thermompnn = dfs[\"merged\"]\n",
        "aggregation_dms_predictions = dfs[\"agg\"]\n",
        "pos = np.arange(1,len(agg_thermompnn[\"no_sa\"].values[0])+1,1)\n",
        "matrix_agg = np.zeros((len(AminoAcids),len(agg_thermompnn[\"no_sa\"].values[0])))\n",
        "xlabel = []\n",
        "\n",
        "#Makes the columns the WT amino acid position\n",
        "for col_wt in range(0,len(pos)):\n",
        "    #Iterates through each amino acid substitution as the row\n",
        "    for row_sub in range(len(AminoAcids)):\n",
        "        curr = agg_thermompnn.query(\"\"\"  position_mut == \"{}\" and mutant_AA == \"{}\" \"\"\".format(pos[col_wt],AminoAcids[row_sub]))\n",
        "\n",
        "        if aggregation_dms_predictions.query(\"\"\" position_mut == \"wt\" \"\"\")[\"no_sa\"].values[0][col_wt] == AminoAcids[row_sub]:\n",
        "            xlabel.append(AminoAcids[row_sub]+str(pos[col_wt]))\n",
        "            matrix_agg[row_sub,col_wt]=0\n",
        "        elif len(curr) > 0:\n",
        "            if curr[\"delta_score\"].values[0] > 0 and curr[\"ddG_pred\"].values[0] <0: #agg res, stabilizing\n",
        "              matrix_agg[row_sub,col_wt]=1\n",
        "            elif curr[\"delta_score\"].values[0] > 0 and curr[\"ddG_pred\"].values[0] >0: #agg res, destabilizing\n",
        "              matrix_agg[row_sub,col_wt]=0.5\n",
        "            elif curr[\"delta_score\"].values[0] < 0 and curr[\"ddG_pred\"].values[0] <0: #agg promoting, stabilizing\n",
        "              matrix_agg[row_sub,col_wt]=-0.5\n",
        "            else:\n",
        "              matrix_agg[row_sub,col_wt]=-1 #agg promoting, destabilizing\n",
        "\n",
        "        else:\n",
        "            matrix_agg[row_sub,col_wt]=np.nan\n",
        "\n",
        "# Map predictions to integer bins\n",
        "value_to_bin = {\n",
        "    -1: 0,\n",
        "    -0.5: 1,\n",
        "    0.0: 2,\n",
        "    0.5: 3,\n",
        "    1: 4\n",
        "}\n",
        "\n",
        "# Build categorical matrix with integer labels\n",
        "cat_matrix = np.full_like(matrix_agg, fill_value=np.nan, dtype=float)\n",
        "\n",
        "for i in range(matrix_agg.shape[0]):\n",
        "    for j in range(matrix_agg.shape[1]):\n",
        "        val = matrix_agg[i, j]\n",
        "        if not np.isnan(val):\n",
        "            cat_matrix[i, j] = value_to_bin[val]\n",
        "\n",
        "# Categorical legend labels\n",
        "legend_labels = {\n",
        "    -1: \"Aggregation Promoting &\\nDestabilizing Mutation\",\n",
        "    -0.5: \"Aggregation Promoting &\\nStabilizing Mutation\",\n",
        "    0.0: \"WT\",\n",
        "    0.5: \"Aggregation Resistance &\\nDestabilizing Mutation\",\n",
        "    1: \"Aggregation Resistance &\\nStabilizing Mutation\"\n",
        "}\n",
        "\n",
        "legend_colors = {\n",
        "    -1: \"tomato\",\n",
        "    -0.5: \"deepskyblue\",\n",
        "    0.0: \"white\",\n",
        "    0.5: \"mediumorchid\",\n",
        "    1: \"yellowgreen\"\n",
        "}\n",
        "colors = [\"tomato\",\"deepskyblue\",  \"white\", \"mediumorchid\", \"yellowgreen\"]\n",
        "cmap = mcolors.ListedColormap(colors)\n",
        "\n",
        "handles = [\n",
        "    mpatches.Patch(facecolor=colors[value_to_bin[val]], label=label, edgecolor='black')\n",
        "    for val, label in legend_labels.items()\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(20,6))\n",
        "\n",
        "# Heatmap plot\n",
        "ax = sns.heatmap(\n",
        "    cat_matrix,\n",
        "    cmap=cmap,\n",
        "    vmin=0, vmax=4,\n",
        "    cbar=False,\n",
        "    yticklabels=AminoAcids,\n",
        "    xticklabels=xlabel,\n",
        "    linewidths=0.1,\n",
        "    linecolor='lightgray'\n",
        ")\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=12)\n",
        "ax.set_yticklabels(ax.get_yticklabels(), rotation=0, fontsize=12)\n",
        "\n",
        "# WT dots\n",
        "wtseq = aggregation_dms_predictions.query(\"\"\" position_mut == \"wt\" \"\"\")[\"no_sa\"].values[0]\n",
        "for i in range(len(wtseq)):\n",
        "    plt.scatter(i+0.5, AminoAcids.index(wtseq[i])+0.5, s=30, color='black')\n",
        "\n",
        "n = aggregation_dms_predictions.query(\"\"\" position_mut == \"wt\" \"\"\")[\"ID\"].values[0]\n",
        "plt.title(\"Comparison of Aggregation and ThermoMPNN Predictions\", fontsize = 16)\n",
        "\n",
        "# Legend on the right outside plot\n",
        "plt.legend(\n",
        "    handles=handles,\n",
        "    loc='center left',\n",
        "    bbox_to_anchor=(1.02, 0.5),   # push legend outside right side\n",
        "    borderaxespad=0,\n",
        "    frameon=False, fontsize = 14\n",
        ")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sPa7cblsVq92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Scatterplot Comparing ThermoMPNN  and Aggregation Predictions\n",
        "!pip install -q plotly\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "\n",
        "# Define aggregation effect categories\n",
        "def combined_effect(row):\n",
        "    if row['delta_score'] > 0 and row['ddG_pred'] < 0:\n",
        "        return 'Aggregation Resistance & Stabilizing'\n",
        "    elif row['delta_score'] < 0 and row['ddG_pred'] < 0:\n",
        "        return 'Aggregation Promoting & Stabilizing'\n",
        "    elif row['delta_score'] > 0 and row['ddG_pred'] > 0:\n",
        "        return 'Aggregation Resistance & Destabilizing'\n",
        "    else:\n",
        "        return 'Aggregation Promoting & Destabilizing'\n",
        "\n",
        "agg_thermompnn['Combined_Effect'] = agg_thermompnn.apply(combined_effect, axis=1)\n",
        "\n",
        "# Map heatmap colors\n",
        "agg_colors = {\n",
        "    'Aggregation Resistance & Stabilizing': 'yellowgreen',\n",
        "    'Aggregation Promoting & Stabilizing': 'deepskyblue',\n",
        "    'Aggregation Resistance & Destabilizing': 'mediumorchid',\n",
        "    'Aggregation Promoting & Destabilizing': 'tomato'\n",
        "}\n",
        "\n",
        "agg_thermompnn[\"delta_agg_score\"]=agg_thermompnn[\"delta_score\"]\n",
        "\n",
        "fig = px.scatter(agg_thermompnn, x='ddG_pred', y='delta_agg_score', color='Combined_Effect',custom_data=agg_thermompnn[['original_AA','position_mut', 'mutant_AA','delta_agg_score','ddG_pred']],color_discrete_map=agg_colors)\n",
        "fig.update_layout(width=1200, height=800,plot_bgcolor='white', paper_bgcolor='white' )\n",
        "\n",
        "#Get axis limits\n",
        "x_min, x_max = agg_thermompnn['ddG_pred'].min(), agg_thermompnn['ddG_pred'].max()\n",
        "y_min, y_max = agg_thermompnn['delta_agg_score'].min(), agg_thermompnn['delta_agg_score'].max()\n",
        "\n",
        "#Add vertical line at x=0\n",
        "fig.add_shape(\n",
        "    type=\"line\",\n",
        "    x0=0, x1=0,\n",
        "    y0=y_min, y1=y_max,\n",
        "    line=dict(color=\"black\", width=2.5, dash=\"dash\")\n",
        ")\n",
        "\n",
        "# Add horizontal line at y=0\n",
        "fig.add_shape(\n",
        "    type=\"line\",\n",
        "    x0=x_min, x1=x_max,\n",
        "    y0=0, y1=0,\n",
        "    line=dict(color=\"black\", width=2.5, dash=\"dash\")\n",
        ")\n",
        "fig.update_xaxes(showgrid=True, gridcolor='lightgrey', gridwidth=1)\n",
        "fig.update_yaxes(showgrid=True, gridcolor='lightgrey', gridwidth=1)\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title=\"ΔΔG (kcal/mol)<br>Stability Prediction\",\n",
        "    yaxis_title=\"Aggregation Prediction<br>Δlog2(Fold Change)\")\n",
        "\n",
        "fig.update_traces(\n",
        "    hovertemplate=(\n",
        "        \"Original AA: %{customdata[0]}<br>\"\n",
        "        \"Position: %{customdata[1]}<br>\"\n",
        "        \"Mutant AA: %{customdata[2]}<br>\"\n",
        "        \"ΔAgg Score: %{customdata[3]:.2g}<br>\"\n",
        "        \"ΔΔG Pred: %{customdata[4]:.2g}<br>\"\n",
        "        \"<extra></extra>\"))\n",
        "\n",
        "fig.show()\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_rQYZhGQWeIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Display Combined Results as an Interactive Table\n",
        "from google.colab import data_table\n",
        "df = dfs[\"merged\"][['ID', 'no_sa', 'position_mut', 'mutant_AA',\n",
        "             'original_AA', 'score_agg', 'delta_score_agg', 'ddG_pred']]\n",
        "data_table.enable_dataframe_formatter()\n",
        "data_table.DataTable(df, include_index=True, num_rows_per_page=10)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "9VQtVYU7WkS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "atRBAigwWk6L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}